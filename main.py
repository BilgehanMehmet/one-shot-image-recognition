import numpy as npimport tensorflow as tfimport matplotlib.pyplot as pltfrom loader import Loader from omniglot import Omniglotimport osimport cv2import utilsdef calc_one_shot_acc(nn,sess,test_data,val_data,n_trials_per_iter,n_trials):    val_acc = 0    one_shot_acc = 0    for _ in range(n_trials // n_trials_per_iter):         test_imgs, train_imgs, labels = test_data.generateOneShotTrials(test_data.X_validation,size=n_trials_per_iter)                  val_acc += utils.get_val_acc(test_imgs,train_imgs,labels,sess,nn,shape=(105,105))        one_shot_test_imgs, one_shot_train_imgs, one_shot_labels = val_data.generateOneShotTrials(val_data.X,size=n_trials_per_iter)                  one_shot_acc += utils.get_val_acc(one_shot_test_imgs,one_shot_train_imgs,one_shot_labels,sess,nn,shape=(105,105))    return val_acc/ n_trials, one_shot_acc/ n_trialsdef display_data(epoch,epoch_loss,epoch_acc,val_acc,one_shot_acc):    print("Epoch:{}\t Epoch Loss:{}\t Train acc:{} \t Val acc:{}\t One Shot acc:{}".format(epoch,epoch_loss,epoch_acc,val_acc,one_shot_acc))    print('{{"metric" : "Loss", "value":{}}}'.format(epoch_loss))    print('{{"metric" : "Training Accuracy", "value":{}}}'.format(epoch_acc))    print('{{"metric" : "Validation Accuracy", "value":{}}}'.format(val_acc))    print('{{"metric" : "One-shot Accuracy", "value":{}}}'.format(one_shot_acc))def train(hyperparameters,train_data,test_data,val_data,epochs,batch_size,drawer_size):    # CNN = Omniglot(shape=(105,105),cost_mode="binary_cross_entropy")    CNN = Omniglot(shape=(105,105),cost_mode="contrastive_loss")    CNN.forward_prop()    # CNN.compute_cost(mode = "l2_on")    CNN.compute_cost(mode = "l2_off",margin=4.)    # CNN.optimize(optimizer="Momentum")    CNN.optimize(optimizer="Adam",layer_wise=False,learning_rate=0.35)    CNN.accuracy()    saver = tf.train.Saver()    filepath = "/output/conv_siamese_model"    seed = 1     learning_rate_multiplier = 0.99    momentum_multiplier = 1.01    with tf.Session() as sess:        sess.run(tf.global_variables_initializer())        # saver.restore(sess,"/floyd/input/model/conv_siamese_model_50.ckpt")        # print("conv_siamese_model_50.ckpt is restored.")        for epoch in range(epochs+1):            epoch_loss = 0            epoch_acc = 0            val_acc = 0            one_shot_acc = 0            n_trials_per_iter = 10            n_trials = n_trials_per_iter * 40            training_batch = train_data.get_training_pairs(batch_size= batch_size, drawer_size= drawer_size, seed=seed)            seed += ((train_data.X.shape[0] * train_data.X.shape[1]) // training_batch[0][0].shape[0])                   for counter, batch in enumerate(training_batch):                # print("In batch:{}".format(counter))                X1 = batch[0]                X2 = batch[1]                Y  = batch[2]                _, c, a= sess.run([CNN.optimizer,CNN.cost,CNN.accuracy], feed_dict={                    CNN.X:  X1,                    CNN.X2: X2,                    CNN.Y:  Y,                    CNN.learning_rates[0]:hyperparameters[0]   * (learning_rate_multiplier** epoch),#0.5                    CNN.learning_rates[1]:hyperparameters[1] * (learning_rate_multiplier* epoch),                    CNN.learning_rates[2]:hyperparameters[2]  * (learning_rate_multiplier** epoch),                    CNN.learning_rates[3]:hyperparameters[3]  * (learning_rate_multiplier** epoch),                    CNN.learning_rates[4]:hyperparameters[4]  * (learning_rate_multiplier** epoch),                    CNN.learning_rates[5]:hyperparameters[5]  * (learning_rate_multiplier** epoch),#90% of prvs layer                    CNN.momentums[0]:hyperparameters[6]  * (momentum_multiplier** epoch),                    CNN.momentums[1]:hyperparameters[7]  * (momentum_multiplier** epoch),                    CNN.momentums[2]:hyperparameters[8]  * (momentum_multiplier** epoch),                    CNN.momentums[3]:hyperparameters[9]  * (momentum_multiplier** epoch),                    CNN.momentums[4]:hyperparameters[10]  * (momentum_multiplier** epoch),                    CNN.momentums[5]:hyperparameters[11]  * (momentum_multiplier** epoch)                                    })                epoch_acc += (a/len(training_batch))                epoch_loss += (c/ len(training_batch))            val_acc,one_shot_acc = calc_one_shot_acc(CNN,sess,test_data,val_data,n_trials_per_iter,n_trials)            display_data(epoch,epoch_loss,epoch_acc,val_acc,one_shot_acc)            if ((epoch % 10 == 0) and epoch != 0):                print("Saving the model...")                saver.save(sess,filepath + "_" + str(epoch+50) + ".ckpt")                if epoch >= 50:                    learning_rate_multiplier = 0.9                    momentum_multiplier = 1.1    if __name__ == "__main__":    train_data = Loader(n_examples=100,mode="train_split",path="/floyd/input/omniglot_dataset",normalise= True)    test_data  = Loader(n_examples=20,mode=None,path="/floyd/input/val_set",normalise=True)     hyperparameters = [                        0.0183,# 0.05,# 0.1,                        0.0183,# 0.05,#0.1,                        0.0183,#0.05,#0.1,                        0.00915,# 0.025,#0.05,                        0.00183,#0.005,#0.01,                        0.000183,# 0.0005,#0.001,                        0.6,# 0.5,# 0.5,                        0.6,# 0.5,# 0.5,                        0.6,# 0.5,# 0.5,                        0.6,# 0.5,# 0.5,                        0.6,# 0.5,# 0.5,                        0.6# 0.5# 0.5              ]    print("Hyperparameters:{}".format(hyperparameters))    train(hyperparameters,train_data,train_data,test_data,epochs=300,batch_size=128,drawer_size=2)   